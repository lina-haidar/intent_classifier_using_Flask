# intent_classifier_using_Flask



How to run the project: 
    python server.py --model "path to the model ex: ../Intent_Classification.h5"



Then go to http://127.0.0.1:5000. On the user interface, click on 'load model'. If the model gets downloaded successfully, the input box appears where you can enter the queries. Type in the query and click on 'predict' to get the output. 

If the model is not loaded, you'll get a message: Status: not ready. 
